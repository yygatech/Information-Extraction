{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task3_1.py\n",
    "\n",
    "# function: sentence tokenize with filter\n",
    "# argument: corpus string\n",
    "# return: tokenized the corpus as sentences\n",
    "def _filter_sent_tokenize(corpus):\n",
    "    ### 3.1.1\n",
    "    # tokenize into sentences\n",
    "    from nltk.tokenize import sent_tokenize as st\n",
    "\n",
    "    original_sentences = st(corpus)\n",
    "\n",
    "    # filter sentences\n",
    "    sentences = [sentence for sentence in original_sentences if len(sentence) > 5]\n",
    "    \n",
    "    # show sentences\n",
    "#     n_sent = len(sentences)\n",
    "#     for i in range(3):\n",
    "#         print(sentences[i])\n",
    "#     print(\"number of sentences:\", n_sent)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# function: word tokenize\n",
    "# argument: sentences as strings\n",
    "# return: tokenized sentences as a list of lists of words\n",
    "def _word_tokenize(sentences):\n",
    "    ### 3.1.2\n",
    "    # tokenize into words\n",
    "    from nltk.tokenize import word_tokenize as wt\n",
    "    \n",
    "    # list of lists of words\n",
    "    n_sent = len(sentences)\n",
    "    words_all = [[] for i in range(n_sent)]\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        words_all[i] = wt(sentence)\n",
    "\n",
    "    # show words\n",
    "#     for i in range(3):\n",
    "#         print(words_all[i])\n",
    "        \n",
    "    return words_all\n",
    "\n",
    "# function: sentence and word tokenize\n",
    "# argument: corpus as a string\n",
    "# return: (sentences, tokenized sentences)\n",
    "def _task3_1(corpus):\n",
    "    ## 3.1\n",
    "    # tokenize the statements into sentences and words\n",
    "    sentences = _filter_sent_tokenize(corpus)\n",
    "    words_all = _word_tokenize(sentences)\n",
    "    \n",
    "    return sentences, words_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
