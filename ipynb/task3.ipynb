{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences\n",
      "The name \"music\" contains two ideas, both of them important in our modern use of the term: The general meaning is that of \"a pleasing modulation of sounds.\"\n",
      "words_all\n",
      "['The', 'name', '``', 'music', \"''\", 'contains', 'two', 'ideas', ',', 'both', 'of', 'them', 'important', 'in', 'our', 'modern', 'use', 'of', 'the', 'term', ':', 'The', 'general', 'meaning', 'is', 'that', 'of', '``', 'a', 'pleasing', 'modulation', 'of', 'sounds', '.', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "# task3.py\n",
    "# How to install and use nltk?\n",
    "# https://www.nltk.org/install.html\n",
    "\n",
    "# How to download nltk data?\n",
    "# https://www.nltk.org/data.html\n",
    "# command line $ python3\n",
    "# python3 >> import nltk\n",
    "# python3 >> nltk.download()\n",
    "# download directory: /usr/local/share/nltk_data\n",
    "# download what you will need\n",
    "\n",
    "import task2\n",
    "import task3_1\n",
    "\n",
    "# load corpus\n",
    "corpus = task2._load_corpus(\"corpus.txt\")\n",
    "\n",
    "## 3.1\n",
    "sentences, words_all = task3_1._task3_1(corpus)\n",
    "\n",
    "# TEST\n",
    "# print(\"sentences\")\n",
    "# print(sentences[1:2][0])\n",
    "\n",
    "# print(\"words_all\")\n",
    "# print(words_all[1:2][0])\n",
    "\n",
    "## 3.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Music has to do with tones, sounds selected on account of their musical quality and relations.']\n",
      "Music\tNN\t2\tnsubj\n",
      "has\tVBZ\t0\tROOT\n",
      "to\tTO\t4\tmark\n",
      "do\tVB\t2\txcomp\n",
      "with\tIN\t6\tcase\n",
      "tones\tNNS\t4\tnmod\n",
      ",\t,\t2\tpunct\n",
      "sounds\tVBZ\t9\tauxpass\n",
      "selected\tVBN\t2\tdep\n",
      "on\tIN\t11\tcase\n",
      "account\tNN\t9\tnmod\n",
      "of\tIN\t15\tcase\n",
      "their\tPRP$\t15\tnmod:poss\n",
      "musical\tJJ\t15\tamod\n",
      "quality\tNN\t11\tnmod\n",
      "and\tCC\t15\tcc\n",
      "relations\tNNS\t15\tconj\n",
      ".\t.\t2\tpunct\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 3.4 (updated version)\n",
    "# perform dependency parsing \n",
    "# or full-syntactic parsing \n",
    "# to parse tree-based patterns as features\n",
    "\n",
    "### 3.4.0 preparation\n",
    "# Setup CoreNLP with Python:\n",
    "# https://www.khalidalnajjar.com/setup-use-stanford-corenlp-server-python/\n",
    "# Download Stanford CoreNLP:\n",
    "# https://stanfordnlp.github.io/CoreNLP/index.html#download\n",
    "# Unzip to local directory:\n",
    "# for example: ../resources/stanford-corenlp-full-2018-10-05/\n",
    "# Run Stanford CoreNLP Server in command line:\n",
    "# java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators \"tokenize,ssplit,pos,lemma,parse,sentiment\" -port 9000 -timeout 30000\n",
    "\n",
    "# nlkt.parse API:\n",
    "# http://www.nltk.org/api/nltk.parse.html#nltk.parse.corenlp.GenericCoreNLPParser\n",
    "\n",
    "### 3.4.1 CoreNLP Dependency Parser\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser as DP\n",
    "dep_parser = DP(url='http://localhost:9000')\n",
    "\n",
    "# example:\n",
    "# parse, = dep_parser.raw_parse(\n",
    "#     'The quick brown fox jumps over the lazy dog.'\n",
    "# )\n",
    "# print(parse.to_conll(4))\n",
    "\n",
    "parse = dep_parser.raw_parse_sents(sentences[5:6])\n",
    "print(sentences[5:6])\n",
    "\n",
    "# show parsed results:\n",
    "for itr_tree in parse:\n",
    "    for tree in itr_tree:\n",
    "        print(tree.to_conll(4))\n",
    "#         print(tree.tree())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Music has to do with tones, sounds selected on account of their musical quality and relations.']\n",
      "                                                  ROOT                                                              \n",
      "                                                   |                                                                 \n",
      "                                                  SINV                                                              \n",
      "            _______________________________________|______________________________________________________________   \n",
      "           S                          |    |                                   |                                  | \n",
      "   ________|___                       |    |                                   |                                  |  \n",
      "  |            VP                     |    |                                   |                                  | \n",
      "  |     _______|___                   |    |                                   |                                  |  \n",
      "  |    |           S                  |    |                                   |                                  | \n",
      "  |    |           |                  |    |                                   |                                  |  \n",
      "  |    |           VP                 |    |                                   NP                                 | \n",
      "  |    |    _______|___               |    |        ___________________________|______                            |  \n",
      "  |    |   |           VP             |    |       |          |                       PP                          | \n",
      "  |    |   |    _______|____          |    |       |          |            ___________|_______                    |  \n",
      "  |    |   |   |            PP        |    |       |          PP          |                   NP                  | \n",
      "  |    |   |   |        ____|____     |    |       |       ___|_____      |            _______|____________       |  \n",
      "  NP   |   |   |       |         NP   |    VP      NP     |         NP    |           NP            |      NP     | \n",
      "  |    |   |   |       |         |    |    |       |      |         |     |     ______|_______      |      |      |  \n",
      "  NN  VBZ  TO  VB      IN       NNS   ,   VBZ     VBN     IN        NN    IN  PRP$    JJ      NN    CC    NNS     . \n",
      "  |    |   |   |       |         |    |    |       |      |         |     |    |      |       |     |      |      |  \n",
      "Music has  to  do     with     tones  ,  sounds selected  on     account  of their musical quality and relations  . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 3.4.2 CoreNLP Parser\n",
    "from nltk.parse.corenlp import CoreNLPParser as CP\n",
    "parser = CP(url='http://localhost:9000')\n",
    "\n",
    "# example:\n",
    "# parse, = parser.raw_parse(\n",
    "#     'The quick brown fox jumps over the lazy dog.'\n",
    "# )\n",
    "# print(parse.pretty_print())\n",
    "\n",
    "parse = parser.raw_parse_sents(sentences[5:6])\n",
    "print(sentences[5:6])\n",
    "\n",
    "# show parsed results:\n",
    "for itr_tree in parse:\n",
    "    for tree in itr_tree:\n",
    "        tree.pretty_print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synsets: [Synset('rice.n.01'), Synset('rice.n.02'), Synset('rice.n.03'), Synset('rice.n.04'), Synset('rice.v.01')] \n",
      "\n",
      "hypernyms: [Synset('grain.n.02'), Synset('starches.n.01')] \n",
      "\n",
      "hyponyms: [Synset('brown_rice.n.01'), Synset('paddy.n.03'), Synset('white_rice.n.01')] \n",
      "\n",
      "meronyms(being a member of): [] \n",
      "\n",
      "Synset('chromatic_color.n.01')\n",
      "Synset('tract.n.01')\n",
      "Synset('environmentalist.n.01')\n",
      "Synset('site.n.01')\n",
      "Synset('vegetable.n.01')\n",
      "Synset('ketamine.n.01')\n",
      "Synset('discolor.v.03')\n",
      "----\n",
      "Synset('cultivated_rice.n.01')\n",
      "holonyms(having members of): [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 3.5\n",
    "# using WordNet,\n",
    "# extract hypernymns, hyponyms, meronyms, and holonyms\n",
    "# as features\n",
    "\n",
    "# nltk WordNet Interface:\n",
    "# http://www.nltk.org/howto/wordnet.html\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# function: get synsets of a word\n",
    "# argument: a word string\n",
    "# return: a list of synsets\n",
    "def __synsets(word):\n",
    "    return wn.synsets(word)\n",
    "\n",
    "# function: get hypernymns of a synset\n",
    "# argument: a synset\n",
    "# return: a list of synsets\n",
    "def __hypernymns(synset):\n",
    "    return synset.hypernyms()\n",
    "\n",
    "# function: get hyponyms of a synset\n",
    "# argument: a synset\n",
    "# return: a list of synsets\n",
    "def __hyponyms(synset):\n",
    "    return synset.hyponyms()\n",
    "\n",
    "# function: get meronyms of a synset\n",
    "# argument: a synset\n",
    "# return: a list of synsets\n",
    "def __meronyms(synset):\n",
    "    return synset.member_holonyms()\n",
    "\n",
    "# TODO?\n",
    "# function: get holonyms of a synset\n",
    "# argument: a synset\n",
    "# return: a list of synsets\n",
    "def __holonyms(synset):#parts\n",
    "    # TEST\n",
    "    for synset in wn.synsets('green'):\n",
    "        for hypernym in synset.hypernyms():\n",
    "            print(hypernym)\n",
    "    print(\"----\")\n",
    "    for synset in wn.synsets('rice'):\n",
    "        for hypernym in synset.part_holonyms():\n",
    "            print(hypernym)\n",
    "    return synset.part_holonyms()\n",
    "\n",
    "# TEST\n",
    "synsets = __synsets('rice')\n",
    "synset = synsets[0]\n",
    "print(\"synsets:\", synsets, \"\\n\")\n",
    "\n",
    "hypernyms = __hypernymns(synset)\n",
    "print(\"hypernyms:\", hypernyms, \"\\n\")\n",
    "\n",
    "hyponyms = __hyponyms(synset)\n",
    "print(\"hyponyms:\", hyponyms, \"\\n\")\n",
    "\n",
    "meronyms = __meronyms(synset)\n",
    "print(\"meronyms(being a member of):\", meronyms, \"\\n\")\n",
    "\n",
    "holonyms = __holonyms(synset)\n",
    "print(\"holonyms(having members of):\", holonyms, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
