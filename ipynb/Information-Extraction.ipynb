{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS6320 Project\n",
    "# Information Extraction\n",
    "\n",
    "# import corpus\n",
    "corpus_path = \"corpus.txt\"\n",
    "corpus = \"\"\n",
    "with open(corpus_path, 'r') as f:\n",
    "    for line in f:\n",
    "        corpus += line.replace('\\n', ' ')\n",
    "# print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿INTRODUCTION.\n",
      "The name \"music\" contains two ideas, both of them important in our modern use of the term: The general meaning is that of \"a pleasing modulation of sounds.\"\n",
      "In this sense the term is used constantly by poets, novelists and even in conversation--as when we speak of the \"music of the forest,\" the \"music of the brook\" or the \"music of nature.\"\n",
      "number of sentecnes: 5056\n"
     ]
    }
   ],
   "source": [
    "## 3.1\n",
    "# tokenize the statements into sentences and words\n",
    "### 3.1.1\n",
    "# tokenize into sentences\n",
    "from nltk.tokenize import sent_tokenize as st\n",
    "\n",
    "original_sentences = st(corpus)\n",
    "\n",
    "# filter sentences\n",
    "sentences = [sentence for sentence in original_sentences if len(sentence) > 5]\n",
    "n_sent = len(sentences)\n",
    "\n",
    "# show sentences\n",
    "for i in range(3):\n",
    "    print(sentences[i])\n",
    "print(\"number of sentecnes:\", n_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffINTRODUCTION', '.']\n",
      "['The', 'name', '``', 'music', \"''\", 'contains', 'two', 'ideas', ',', 'both', 'of', 'them', 'important', 'in', 'our', 'modern', 'use', 'of', 'the', 'term', ':', 'The', 'general', 'meaning', 'is', 'that', 'of', '``', 'a', 'pleasing', 'modulation', 'of', 'sounds', '.', \"''\"]\n",
      "['In', 'this', 'sense', 'the', 'term', 'is', 'used', 'constantly', 'by', 'poets', ',', 'novelists', 'and', 'even', 'in', 'conversation', '--', 'as', 'when', 'we', 'speak', 'of', 'the', '``', 'music', 'of', 'the', 'forest', ',', \"''\", 'the', '``', 'music', 'of', 'the', 'brook', \"''\", 'or', 'the', '``', 'music', 'of', 'nature', '.', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "### 3.1.2\n",
    "# tokenize into words\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "\n",
    "# list of lists of words\n",
    "words_all = [[] for i in range(n_sent)]\n",
    "for i, sentence in enumerate(sentences):\n",
    "    words_all[i] = wt(sentence)\n",
    "    \n",
    "# show words\n",
    "for i in range(3):\n",
    "    print(words_all[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\ufeffINTRODUCTION', 'NN'), ('.', '.')]\n",
      "['NN', '.']\n",
      "['n', '']\n",
      "\n",
      "[('The', 'DT'), ('name', 'NN'), ('``', '``'), ('music', 'NN'), (\"''\", \"''\"), ('contains', 'VBZ'), ('two', 'CD'), ('ideas', 'NNS'), (',', ','), ('both', 'DT'), ('of', 'IN'), ('them', 'PRP'), ('important', 'JJ'), ('in', 'IN'), ('our', 'PRP$'), ('modern', 'JJ'), ('use', 'NN'), ('of', 'IN'), ('the', 'DT'), ('term', 'NN'), (':', ':'), ('The', 'DT'), ('general', 'JJ'), ('meaning', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('of', 'IN'), ('``', '``'), ('a', 'DT'), ('pleasing', 'JJ'), ('modulation', 'NN'), ('of', 'IN'), ('sounds', 'NNS'), ('.', '.'), (\"''\", \"''\")]\n",
      "['DT', 'NN', '``', 'NN', \"''\", 'VBZ', 'CD', 'NNS', ',', 'DT', 'IN', 'PRP', 'JJ', 'IN', 'PRP$', 'JJ', 'NN', 'IN', 'DT', 'NN', ':', 'DT', 'JJ', 'NN', 'VBZ', 'IN', 'IN', '``', 'DT', 'JJ', 'NN', 'IN', 'NNS', '.', \"''\"]\n",
      "['', 'n', '', 'n', '', 'v', '', 'n', '', '', '', '', 'a', '', '', 'a', 'n', '', '', 'n', '', '', 'a', 'n', 'v', '', '', '', '', 'a', 'n', '', 'n', '', '']\n",
      "\n",
      "[('In', 'IN'), ('this', 'DT'), ('sense', 'NN'), ('the', 'DT'), ('term', 'NN'), ('is', 'VBZ'), ('used', 'VBN'), ('constantly', 'RB'), ('by', 'IN'), ('poets', 'NNS'), (',', ','), ('novelists', 'NNS'), ('and', 'CC'), ('even', 'RB'), ('in', 'IN'), ('conversation', 'NN'), ('--', ':'), ('as', 'IN'), ('when', 'WRB'), ('we', 'PRP'), ('speak', 'VBP'), ('of', 'IN'), ('the', 'DT'), ('``', '``'), ('music', 'NN'), ('of', 'IN'), ('the', 'DT'), ('forest', 'NN'), (',', ','), (\"''\", \"''\"), ('the', 'DT'), ('``', '``'), ('music', 'NN'), ('of', 'IN'), ('the', 'DT'), ('brook', 'NN'), (\"''\", \"''\"), ('or', 'CC'), ('the', 'DT'), ('``', '``'), ('music', 'NN'), ('of', 'IN'), ('nature', 'NN'), ('.', '.'), (\"''\", \"''\")]\n",
      "['IN', 'DT', 'NN', 'DT', 'NN', 'VBZ', 'VBN', 'RB', 'IN', 'NNS', ',', 'NNS', 'CC', 'RB', 'IN', 'NN', ':', 'IN', 'WRB', 'PRP', 'VBP', 'IN', 'DT', '``', 'NN', 'IN', 'DT', 'NN', ',', \"''\", 'DT', '``', 'NN', 'IN', 'DT', 'NN', \"''\", 'CC', 'DT', '``', 'NN', 'IN', 'NN', '.', \"''\"]\n",
      "['', '', 'n', '', 'n', 'v', 'v', 'r', '', 'n', '', 'n', '', 'r', '', 'n', '', '', '', '', 'v', '', '', '', 'n', '', '', 'n', '', '', '', '', 'n', '', '', 'n', '', '', '', '', 'n', '', 'n', '', '']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 3.3\n",
    "# part-of-speech (POS) tag the words \n",
    "# to extract lemmas as features\n",
    "# should use word_tokenize before POS tagging\n",
    "\n",
    "from nltk import pos_tag as pt\n",
    "\n",
    "# nltk WordNet Interface:\n",
    "# http://www.nltk.org/howto/wordnet.html\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "pos_tags_all = [[] for i in range(n_sent)]\n",
    "tags_all = [\"\" for i in range(n_sent)]\n",
    "\n",
    "for i, words in enumerate(words_all):\n",
    "    pos_tags = pt(words)\n",
    "    pos_tags_all[i] = pos_tags\n",
    "    tags_all[i] = [pos_tag[1] for pos_tag in pos_tags]\n",
    "\n",
    "# Penn Treebank tags to WordNet tags\n",
    "def _penn2wn(penn_tag):\n",
    "    if penn_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif penn_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif penn_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif penn_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# WordNet (morphy) tags\n",
    "wn_tags_all = [[] for i in range(n_sent)]\n",
    "for i, tags in enumerate(tags_all):\n",
    "    wn_tags = [wn.NOUN for j in range(len(tags))]\n",
    "    for j, tag in enumerate(tags):\n",
    "        wn_tags[j] = _penn2wn(tag)\n",
    "    wn_tags_all[i] = wn_tags\n",
    "\n",
    "# show pos_tags\n",
    "for i in range(3):\n",
    "    print(pos_tags_all[i])\n",
    "    print(tags_all[i])\n",
    "    print(wn_tags_all[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffINTRODUCTION', '.']\n",
      "['The', 'name', '``', 'music', \"''\", 'contain', 'two', 'idea', ',', 'both', 'of', 'them', 'important', 'in', 'our', 'modern', 'use', 'of', 'the', 'term', ':', 'The', 'general', 'meaning', 'be', 'that', 'of', '``', 'a', 'pleasing', 'modulation', 'of', 'sound', '.', \"''\"]\n",
      "['In', 'this', 'sense', 'the', 'term', 'be', 'use', 'constantly', 'by', 'poet', ',', 'novelist', 'and', 'even', 'in', 'conversation', '--', 'a', 'when', 'we', 'speak', 'of', 'the', '``', 'music', 'of', 'the', 'forest', ',', \"''\", 'the', '``', 'music', 'of', 'the', 'brook', \"''\", 'or', 'the', '``', 'music', 'of', 'nature', '.', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "## 3.2\n",
    "# lemmatize the words to extract lemmas as features\n",
    "from nltk.stem import WordNetLemmatizer as LM\n",
    "lm = LM()\n",
    "lemmas_all = [[] for i in range(n_sent)]\n",
    "for i, words in enumerate(words_all):\n",
    "    lemmas = [\"\" for j in range(len(words))]\n",
    "    for j, word in enumerate(words):\n",
    "        wn_tag = wn_tags_all[i][j]\n",
    "        if wn_tag == '':\n",
    "            lemma = lm.lemmatize(word)\n",
    "        else:\n",
    "            lemma = lm.lemmatize(word, wn_tag)\n",
    "        lemmas[j] = lemma\n",
    "    lemmas_all[i] = lemmas\n",
    "    \n",
    "# show lemmas\n",
    "for i in range(3):\n",
    "    print(lemmas_all[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Music has to do with tones, sounds selected on account of their musical quality and relations.']\n",
      "Music\tNN\t2\tnsubj\n",
      "has\tVBZ\t0\tROOT\n",
      "to\tTO\t4\tmark\n",
      "do\tVB\t2\txcomp\n",
      "with\tIN\t6\tcase\n",
      "tones\tNNS\t4\tnmod\n",
      ",\t,\t2\tpunct\n",
      "sounds\tVBZ\t9\tauxpass\n",
      "selected\tVBN\t2\tdep\n",
      "on\tIN\t11\tcase\n",
      "account\tNN\t9\tnmod\n",
      "of\tIN\t15\tcase\n",
      "their\tPRP$\t15\tnmod:poss\n",
      "musical\tJJ\t15\tamod\n",
      "quality\tNN\t11\tnmod\n",
      "and\tCC\t15\tcc\n",
      "relations\tNNS\t15\tconj\n",
      ".\t.\t2\tpunct\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 3.4 (updated version)\n",
    "# perform dependency parsing \n",
    "# or full-syntactic parsing \n",
    "# to parse tree-based patterns as features\n",
    "\n",
    "### 3.4.0 preparation\n",
    "# Setup CoreNLP with Python:\n",
    "# https://www.khalidalnajjar.com/setup-use-stanford-corenlp-server-python/\n",
    "# Download Stanford CoreNLP:\n",
    "# https://stanfordnlp.github.io/CoreNLP/index.html#download\n",
    "# Unzip to local directory:\n",
    "# for example: ../resources/stanford-corenlp-full-2018-10-05/\n",
    "# Run Stanford CoreNLP Server in command line:\n",
    "# java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators \"tokenize,ssplit,pos,lemma,parse,sentiment\" -port 9000 -timeout 30000\n",
    "\n",
    "# nlkt.parse API:\n",
    "# http://www.nltk.org/api/nltk.parse.html#nltk.parse.corenlp.GenericCoreNLPParser\n",
    "\n",
    "### 3.4.1 CoreNLP Dependency Parser\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser as DP\n",
    "dep_parser = DP(url='http://localhost:9000')\n",
    "\n",
    "# example:\n",
    "# parse, = dep_parser.raw_parse(\n",
    "#     'The quick brown fox jumps over the lazy dog.'\n",
    "# )\n",
    "# print(parse.to_conll(4))\n",
    "\n",
    "parse = dep_parser.raw_parse_sents(sentences[5:6])\n",
    "print(sentences[5:6])\n",
    "\n",
    "# show parsed results:\n",
    "for itr_tree in parse:\n",
    "    for tree in itr_tree:\n",
    "        print(tree.to_conll(4))\n",
    "#         print(tree.tree())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Music has to do with tones, sounds selected on account of their musical quality and relations.']\n",
      "                                                  ROOT                                                              \n",
      "                                                   |                                                                 \n",
      "                                                  SINV                                                              \n",
      "            _______________________________________|______________________________________________________________   \n",
      "           S                          |    |                                   |                                  | \n",
      "   ________|___                       |    |                                   |                                  |  \n",
      "  |            VP                     |    |                                   |                                  | \n",
      "  |     _______|___                   |    |                                   |                                  |  \n",
      "  |    |           S                  |    |                                   |                                  | \n",
      "  |    |           |                  |    |                                   |                                  |  \n",
      "  |    |           VP                 |    |                                   NP                                 | \n",
      "  |    |    _______|___               |    |        ___________________________|______                            |  \n",
      "  |    |   |           VP             |    |       |          |                       PP                          | \n",
      "  |    |   |    _______|____          |    |       |          |            ___________|_______                    |  \n",
      "  |    |   |   |            PP        |    |       |          PP          |                   NP                  | \n",
      "  |    |   |   |        ____|____     |    |       |       ___|_____      |            _______|____________       |  \n",
      "  NP   |   |   |       |         NP   |    VP      NP     |         NP    |           NP            |      NP     | \n",
      "  |    |   |   |       |         |    |    |       |      |         |     |     ______|_______      |      |      |  \n",
      "  NN  VBZ  TO  VB      IN       NNS   ,   VBZ     VBN     IN        NN    IN  PRP$    JJ      NN    CC    NNS     . \n",
      "  |    |   |   |       |         |    |    |       |      |         |     |    |      |       |     |      |      |  \n",
      "Music has  to  do     with     tones  ,  sounds selected  on     account  of their musical quality and relations  . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 3.4.2 CoreNLP Parser\n",
    "from nltk.parse.corenlp import CoreNLPParser as CP\n",
    "parser = CP(url='http://localhost:9000')\n",
    "\n",
    "# example:\n",
    "# parse, = parser.raw_parse(\n",
    "#     'The quick brown fox jumps over the lazy dog.'\n",
    "# )\n",
    "# print(parse.pretty_print())\n",
    "\n",
    "parse = parser.raw_parse_sents(sentences[5:6])\n",
    "print(sentences[5:6])\n",
    "\n",
    "# show parsed results:\n",
    "for itr_tree in parse:\n",
    "    for tree in itr_tree:\n",
    "        tree.pretty_print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synsets: [Synset('elephant.n.01'), Synset('elephant.n.02')] \n",
      "\n",
      "hypernyms: [Synset('pachyderm.n.01'), Synset('proboscidean.n.01')] \n",
      "\n",
      "hyponyms: [Synset('african_elephant.n.01'), Synset('gomphothere.n.01'), Synset('indian_elephant.n.01'), Synset('mammoth.n.01'), Synset('rogue_elephant.n.01')] \n",
      "\n",
      "meronyms(being a member of): [Synset('elephantidae.n.01')] \n",
      "\n",
      "holonyms(having members of): -1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 3.5\n",
    "# using WordNet,\n",
    "# extract hypernymns, hyponyms, meronyms, and holonyms\n",
    "# as features\n",
    "\n",
    "# nltk WordNet Interface:\n",
    "# http://www.nltk.org/howto/wordnet.html\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# function: get synsets of a word\n",
    "# argument: a word string\n",
    "# return: a list of synsets\n",
    "def __synsets(word):\n",
    "    return wn.synsets(word)\n",
    "\n",
    "# function: get hypernymns of a synset\n",
    "# argument: a synset\n",
    "# return: a list of synsets\n",
    "def __hypernymns(synset):\n",
    "    return synset.hypernyms()\n",
    "\n",
    "# function: get hyponyms of a synset\n",
    "# argument: a synset\n",
    "# return: a list of synsets\n",
    "def __hyponyms(synset):\n",
    "    return synset.hyponyms()\n",
    "\n",
    "# function: get meronyms of a synset\n",
    "# argument: a synset\n",
    "# return: a list of synsets\n",
    "def __meronyms(synset):\n",
    "    return synset.member_holonyms()\n",
    "\n",
    "# TODO?\n",
    "# function: get holonyms of a synset\n",
    "# argument: a synset\n",
    "# return: a list of synsets\n",
    "def __holonyms(synset):\n",
    "    return -1\n",
    "\n",
    "# test\n",
    "synsets = __synsets('elephant')\n",
    "synset = synsets[0]\n",
    "print(\"synsets:\", synsets, \"\\n\")\n",
    "\n",
    "hypernyms = __hypernymns(synset)\n",
    "print(\"hypernyms:\", hypernyms, \"\\n\")\n",
    "\n",
    "hyponyms = __hyponyms(synset)\n",
    "print(\"hyponyms:\", hyponyms, \"\\n\")\n",
    "\n",
    "meronyms = __meronyms(synset)\n",
    "print(\"meronyms(being a member of):\", meronyms, \"\\n\")\n",
    "\n",
    "holonyms = __holonyms(synset)\n",
    "print(\"holonyms(having members of):\", holonyms, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
